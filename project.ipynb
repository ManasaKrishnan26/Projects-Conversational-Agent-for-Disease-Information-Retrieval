{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "from Bio import Entrez\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup  # For HTML parsing\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DISEASES DATA FROM ORPHANET FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of rare diseases are available here  -  https://www.orphadata.com/classifications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files_from_folder(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    return files\n",
    "\n",
    "def parse_orphanet_xml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    diseases = []\n",
    "    for disorder in root.findall('.//Disorder'):\n",
    "        name = disorder.find('.//Name[@lang=\"en\"]')\n",
    "        orpha_code = disorder.find('.//OrphaCode')\n",
    "        if name is not None and orpha_code is not None:\n",
    "            diseases.append({'name': name.text, 'orpha_code': orpha_code.text})\n",
    "    return diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases_dict = {}\n",
    "for file in read_files_from_folder('Rare_Diseases'):\n",
    "    if file.endswith('.xml'):\n",
    "        diseases = parse_orphanet_xml('Rare_Diseases/' + file)\n",
    "        file_name = file.split('.')[0]\n",
    "        diseases_dict[file_name] = diseases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------End Orphanet data------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Pubmed Data fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = 'abc@gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pubmed(query, max_results=10):\n",
    "    Entrez.email = EMAIL  # Always provide your email\n",
    "    query_with_filter = query + \" AND free full text[sb]\"  # Adding the free full text filter\n",
    "    handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='relevance', \n",
    "                            retmax=max_results,\n",
    "                            retmode='xml', \n",
    "                            term=query_with_filter)\n",
    "    results = Entrez.read(handle)\n",
    "\n",
    "    if results['IdList'] == []:\n",
    "        handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='relevance', \n",
    "                            retmax=max_results,\n",
    "                            retmode='xml', \n",
    "                            term=query)\n",
    "        \n",
    "        results = Entrez.read(handle)\n",
    "    return results['IdList']\n",
    "\n",
    "\n",
    "def fetch_pubmed_details(id_list):\n",
    "    Entrez.email = EMAIL \n",
    "    if len(id_list) == 0:\n",
    "        return None\n",
    "    ids = ','.join(id_list)\n",
    "    handle = Entrez.efetch(db='pubmed', id=ids, retmode='xml')\n",
    "    papers = Entrez.read(handle)\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_articles = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diseases = set()\n",
    "for disease_name, diseases in diseases_dict.items():\n",
    "    for disease in diseases:\n",
    "        all_diseases.add(disease['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease in all_diseases:\n",
    "    if disease in disease_articles and disease_articles[disease] != []:\n",
    "        continue    \n",
    "    query = f'{disease}'\n",
    "    disease_articles[disease] = search_pubmed(query, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logged on 8th Dec - 12:09 AM - json dumped at 12:10 AM\n",
    "with open('disease_articles.json', 'w') as f:\n",
    "    json.dump(disease_articles, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file for disease articles if present else create a new one\n",
    "with open('disease_articles.json', 'r') as f:\n",
    "    disease_articles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_list = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for disease, ids in tqdm(disease_articles.items()):\n",
    "    if disease in papers_list and papers_list[disease] != []:\n",
    "        continue\n",
    "    papers_list[disease] = fetch_pubmed_details(ids)\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_articles_new = {key: value for key, value in disease_articles.items() if value}\n",
    "len(disease_articles_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = list()\n",
    "\n",
    "def get_article_details(diseases_dict:dict, disease_articles:dict,combined_data:list):\n",
    "    for category, diseases in diseases_dict.items():\n",
    "        print(f\"Processing {category}...\")\n",
    "        if os.path.exists(f\"combined_data/{category}.json\"):\n",
    "            continue\n",
    "\n",
    "        for disease in tqdm(diseases):\n",
    "            disease_data = {\n",
    "                'name': disease['name'],\n",
    "                'orpha_code': disease['orpha_code'],\n",
    "                'articles': []\n",
    "            }\n",
    "            \n",
    "            if disease['name'] in disease_articles:\n",
    "                ids = disease_articles_new[disease['name']][:5]\n",
    "                papers = fetch_pubmed_details(ids)\n",
    "                time.sleep(0.5)\n",
    "                if papers:\n",
    "                    for paper in papers['PubmedArticle']:\n",
    "                        pmid = paper['MedlineCitation']['PMID'].title()\n",
    "                        # Extract necessary details from each paper\n",
    "                        article_data = paper['MedlineCitation']['Article']\n",
    "                        if article_data['ELocationID'] and article_data['ELocationID'][0].attributes['EIdType'] == 'doi':\n",
    "                            doi = article_data['ELocationID'][0].title()\n",
    "\n",
    "                        article_url = f\"https://doi.org/{doi}\" if doi else ''\n",
    "                        title = article_data['ArticleTitle']\n",
    "                        abstract = paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0] if 'Abstract' in paper['MedlineCitation']['Article'] else ''\n",
    "                        disease_data['articles'].append({'PMID':pmid, 'title': title, 'abstract': abstract, 'article_url': article_url})\n",
    "\n",
    "            combined_data.append(disease_data)\n",
    "\n",
    "\n",
    "        # Create the \"combined_data\" folder if it doesn't exist\n",
    "        if not os.path.exists(\"combined_data\"):\n",
    "            os.makedirs(\"combined_data\")\n",
    "\n",
    "        # Dump the combined_data dictionary to a JSON file in the \"combined_data\" folder\n",
    "        with open(f\"combined_data/{category}.json\", \"w\") as f:\n",
    "            json.dump(combined_data, f)\n",
    "\n",
    "        combined_data.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_article_details(diseases_dict, disease_articles_new,combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_text_from_doi(doi_url):\n",
    "    # Use Selenium to handle JavaScript-enabled requests\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('window-size=1920x1080')  # Set the window size\n",
    "    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36')\n",
    "    options.add_argument('--headless')  # Run Chrome in headless mode\n",
    "    with webdriver.Chrome(options=options) as driver:\n",
    "        driver.get(doi_url)\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "\n",
    "    # Parse the HTML using BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    article_tag = soup.find('article')\n",
    "    if article_tag:\n",
    "        article_text = article_tag.get_text()\n",
    "    else:\n",
    "        article_text = soup.get_text()\n",
    "\n",
    "    return article_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_html(html_content):\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    article_tag = soup.find('article')\n",
    " \n",
    "    # Remove script and style elements\n",
    "    for script_or_style in soup(['script', 'style']):\n",
    "        script_or_style.extract()\n",
    "\n",
    "    # Get text\n",
    "    text = ''\n",
    "    if article_tag:\n",
    "        text = article_tag.get_text()\n",
    "    else:\n",
    "        text = soup.get_text()\n",
    "\n",
    "    # Break into lines and remove leading and trailing space on each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "\n",
    "    # Break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "\n",
    "    # Drop blank lines and remove non-ascii characters\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('window-size=1920x1080')  # Set the window size\n",
    "options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36')\n",
    "options.add_argument('--headless')  # Run Chrome in headless mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_folder = 'combined_data'\n",
    "for file_name in (os.listdir(combined_data_folder)):\n",
    "    print(f\"Processing {file_name}...\")\n",
    "    if os.path.exists(f\"final_data/{file_name}\"):\n",
    "        continue\n",
    "    file_path = os.path.join(combined_data_folder, file_name)\n",
    "    with open(file_path, 'r') as f:\n",
    "        final_data = json.load(f)\n",
    "        # Process the data here\n",
    "        with webdriver.Chrome(options=options) as driver:\n",
    "            for data in tqdm(final_data[:250]):\n",
    "                for article in data['articles']:\n",
    "                    if 'full_text' in article:\n",
    "                        continue\n",
    "                    if article['article_url']:\n",
    "                        driver.get(article['article_url'])\n",
    "                        time.sleep(4)\n",
    "                        html = driver.page_source\n",
    "                        # Parse the HTML using BeautifulSoup\n",
    "                        article_text = clean_html(html)\n",
    "                        article['full_text'] = article_text        # Add the loaded file to the list\n",
    "\n",
    "         \n",
    "        # Create the \"final_data\" folder if it doesn't exist\n",
    "        if not os.path.exists(\"final_data\"):\n",
    "            os.makedirs(\"final_data\")\n",
    "\n",
    "        # Dump the combined_data dictionary to a JSON file in the \"final_data\" folder\n",
    "        with open(f\"final_data/{file_name}\", \"w\") as f:\n",
    "            json.dump(final_data, f)  \n",
    "\n",
    "        final_data = []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing and cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chintanaddoni/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_data_folder = 'final_data'\n",
    "combined_data_df = []\n",
    "df = pd.DataFrame(columns=['name', 'orpha_code', 'PMID', 'title', 'abstract', 'article_url', 'full_text'])\n",
    "\n",
    "for file_name in os.listdir(final_data_folder):\n",
    "    file_path = os.path.join(final_data_folder, file_name)\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        combined_data_df = []\n",
    "        for disease_data in data:\n",
    "            name = disease_data['name']\n",
    "            orpha_code = disease_data['orpha_code']\n",
    "            articles = disease_data['articles']\n",
    "            for article in articles:\n",
    "                if 'full_text' in article: \n",
    "                    if len(article['full_text']) < 1000:\n",
    "                        article['full_text'] = article['abstract']\n",
    "                    combined_data_df.append([name, orpha_code, article['PMID'], article['title'], article['abstract'], article['article_url'], article['full_text']])\n",
    "                else:\n",
    "                    article['full_text'] = article['abstract']\n",
    "                    combined_data_df.append([name, orpha_code, article['PMID'], article['title'], article['abstract'], article['article_url'], article['full_text']])\n",
    "\n",
    "    # Append combined_data_df to df using pd.concat()\n",
    "    df = pd.concat([df, pd.DataFrame(combined_data_df, columns=df.columns)], ignore_index=True)\n",
    "    df.drop_duplicates(subset = df.columns.difference(['full_text', 'article_url']),inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27507, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>orpha_code</th>\n",
       "      <th>PMID</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>article_url</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>33745447</td>\n",
       "      <td>Diagnostic precision and identification of rar...</td>\n",
       "      <td>Diagnostic precision and the identification of...</td>\n",
       "      <td>https://doi.org/10.1002/Jimd.12306</td>\n",
       "      <td>Journal of Inherited Metabolic DiseaseVolume 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>36401554</td>\n",
       "      <td>Prevalence and mortality among children with a...</td>\n",
       "      <td>We examined the total prevalence, trends in pr...</td>\n",
       "      <td>https://doi.org/10.1002/Bdr2.2129</td>\n",
       "      <td>We examined the total prevalence, trends in pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>27126916</td>\n",
       "      <td>Frederik Ruysch (1638-1731): Historical perspe...</td>\n",
       "      <td>The Peter the Great Museum of Anthropology and...</td>\n",
       "      <td>https://doi.org/10.1002/Ajmg.A.37663</td>\n",
       "      <td>The Peter the Great Museum of Anthropology and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>35644130</td>\n",
       "      <td>A Multicountry Analysis of Prevalence and Mort...</td>\n",
       "      <td>Bladder exstrophy (BE) is a rare but severe b...</td>\n",
       "      <td>https://doi.org/10.1055/S-0042-1748318</td>\n",
       "      <td>Subscribe to RSS\\nPlease copy the URL and add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>33253899</td>\n",
       "      <td>Prevalence and mortality in children with cong...</td>\n",
       "      <td>This study determined the prevalence, mortalit...</td>\n",
       "      <td>https://doi.org/10.1016/J.Annepidem.2020.11.007</td>\n",
       "      <td>Annals of EpidemiologyVolume 56, April 2021, P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name orpha_code      PMID  \\\n",
       "0  Rare teratologic disease      52662  33745447   \n",
       "1  Rare teratologic disease      52662  36401554   \n",
       "2  Rare teratologic disease      52662  27126916   \n",
       "3  Rare teratologic disease      52662  35644130   \n",
       "4  Rare teratologic disease      52662  33253899   \n",
       "\n",
       "                                               title  \\\n",
       "0  Diagnostic precision and identification of rar...   \n",
       "1  Prevalence and mortality among children with a...   \n",
       "2  Frederik Ruysch (1638-1731): Historical perspe...   \n",
       "3  A Multicountry Analysis of Prevalence and Mort...   \n",
       "4  Prevalence and mortality in children with cong...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Diagnostic precision and the identification of...   \n",
       "1  We examined the total prevalence, trends in pr...   \n",
       "2  The Peter the Great Museum of Anthropology and...   \n",
       "3   Bladder exstrophy (BE) is a rare but severe b...   \n",
       "4  This study determined the prevalence, mortalit...   \n",
       "\n",
       "                                       article_url  \\\n",
       "0               https://doi.org/10.1002/Jimd.12306   \n",
       "1                https://doi.org/10.1002/Bdr2.2129   \n",
       "2             https://doi.org/10.1002/Ajmg.A.37663   \n",
       "3           https://doi.org/10.1055/S-0042-1748318   \n",
       "4  https://doi.org/10.1016/J.Annepidem.2020.11.007   \n",
       "\n",
       "                                           full_text  \n",
       "0  Journal of Inherited Metabolic DiseaseVolume 4...  \n",
       "1  We examined the total prevalence, trends in pr...  \n",
       "2  The Peter the Great Museum of Anthropology and...  \n",
       "3  Subscribe to RSS\\nPlease copy the URL and add ...  \n",
       "4  Annals of EpidemiologyVolume 56, April 2021, P...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_citations(text):\n",
    "    # Remove citations references (e.g., [1], [1,2], [1-3])\n",
    "    text = re.sub(r'\\[\\d+(,\\s?\\d+)*(\\s?-\\s?\\d+)?\\]', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    return text\n",
    " \n",
    "\n",
    "def remove_references_section(text):\n",
    "    # Naive approach to remove references section\n",
    "    text = re.sub(r'\\b(references|bibliography)\\b.*', '', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    return text\n",
    "\n",
    "def tokenize_and_clean(text):\n",
    "    # Tokenize into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords and non-alphabetic words\n",
    "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "\n",
    "    # # add stemming\n",
    "    # stemmer = PorterStemmer()\n",
    "    # words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = remove_citations(text)\n",
    "    text = remove_references_section(text)\n",
    "    words = tokenize_and_clean(text)\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['full_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('final_data_cleaned.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>orpha_code</th>\n",
       "      <th>PMID</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>article_url</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>33745447</td>\n",
       "      <td>Diagnostic precision and identification of rar...</td>\n",
       "      <td>Diagnostic precision and the identification of...</td>\n",
       "      <td>https://doi.org/10.1002/Jimd.12306</td>\n",
       "      <td>Journal of Inherited Metabolic DiseaseVolume 4...</td>\n",
       "      <td>journal inherited metabolic diseasevolume issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>36401554</td>\n",
       "      <td>Prevalence and mortality among children with a...</td>\n",
       "      <td>We examined the total prevalence, trends in pr...</td>\n",
       "      <td>https://doi.org/10.1002/Bdr2.2129</td>\n",
       "      <td>We examined the total prevalence, trends in pr...</td>\n",
       "      <td>examined total prevalence trends prevalence mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>27126916</td>\n",
       "      <td>Frederik Ruysch (1638-1731): Historical perspe...</td>\n",
       "      <td>The Peter the Great Museum of Anthropology and...</td>\n",
       "      <td>https://doi.org/10.1002/Ajmg.A.37663</td>\n",
       "      <td>The Peter the Great Museum of Anthropology and...</td>\n",
       "      <td>peter great museum anthropology ethnography ku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>35644130</td>\n",
       "      <td>A Multicountry Analysis of Prevalence and Mort...</td>\n",
       "      <td>Bladder exstrophy (BE) is a rare but severe b...</td>\n",
       "      <td>https://doi.org/10.1055/S-0042-1748318</td>\n",
       "      <td>Subscribe to RSS\\nPlease copy the URL and add ...</td>\n",
       "      <td>subscribe rss please copy url add rss feed rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rare teratologic disease</td>\n",
       "      <td>52662</td>\n",
       "      <td>33253899</td>\n",
       "      <td>Prevalence and mortality in children with cong...</td>\n",
       "      <td>This study determined the prevalence, mortalit...</td>\n",
       "      <td>https://doi.org/10.1016/J.Annepidem.2020.11.007</td>\n",
       "      <td>Annals of EpidemiologyVolume 56, April 2021, P...</td>\n",
       "      <td>annals epidemiologyvolume april pages articlep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name orpha_code      PMID  \\\n",
       "0  Rare teratologic disease      52662  33745447   \n",
       "1  Rare teratologic disease      52662  36401554   \n",
       "2  Rare teratologic disease      52662  27126916   \n",
       "3  Rare teratologic disease      52662  35644130   \n",
       "4  Rare teratologic disease      52662  33253899   \n",
       "\n",
       "                                               title  \\\n",
       "0  Diagnostic precision and identification of rar...   \n",
       "1  Prevalence and mortality among children with a...   \n",
       "2  Frederik Ruysch (1638-1731): Historical perspe...   \n",
       "3  A Multicountry Analysis of Prevalence and Mort...   \n",
       "4  Prevalence and mortality in children with cong...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Diagnostic precision and the identification of...   \n",
       "1  We examined the total prevalence, trends in pr...   \n",
       "2  The Peter the Great Museum of Anthropology and...   \n",
       "3   Bladder exstrophy (BE) is a rare but severe b...   \n",
       "4  This study determined the prevalence, mortalit...   \n",
       "\n",
       "                                       article_url  \\\n",
       "0               https://doi.org/10.1002/Jimd.12306   \n",
       "1                https://doi.org/10.1002/Bdr2.2129   \n",
       "2             https://doi.org/10.1002/Ajmg.A.37663   \n",
       "3           https://doi.org/10.1055/S-0042-1748318   \n",
       "4  https://doi.org/10.1016/J.Annepidem.2020.11.007   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Journal of Inherited Metabolic DiseaseVolume 4...   \n",
       "1  We examined the total prevalence, trends in pr...   \n",
       "2  The Peter the Great Museum of Anthropology and...   \n",
       "3  Subscribe to RSS\\nPlease copy the URL and add ...   \n",
       "4  Annals of EpidemiologyVolume 56, April 2021, P...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  journal inherited metabolic diseasevolume issu...  \n",
       "1  examined total prevalence trends prevalence mo...  \n",
       "2  peter great museum anthropology ethnography ku...  \n",
       "3  subscribe rss please copy url add rss feed rea...  \n",
       "4  annals epidemiologyvolume april pages articlep...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming 'preprocessed_texts' is a list of your preprocessed documents\n",
    "vectorizer = TfidfVectorizer()\n",
    "preprocessed_texts = df['cleaned_text'].values\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_texts)\n",
    "\n",
    "def find_unique_relevant_documents(query, tfidf_matrix, top_n=5):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Use argsort for indices and then unique to filter out duplicates\n",
    "    unique_indices = np.unique(cosine_similarities.argsort()[::-1], return_index=True)[1]\n",
    "    \n",
    "    # Sort unique indices based on original similarity scores\n",
    "    sorted_unique_indices = unique_indices[np.argsort(-cosine_similarities[unique_indices])]\n",
    "\n",
    "    # Select top_n indices\n",
    "    relevant_indices = sorted_unique_indices[:top_n]\n",
    "\n",
    "    return relevant_indices, cosine_similarities[relevant_indices]\n",
    "\n",
    "\n",
    "def summarize(text, language=\"english\", sentences_count = 6):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return ' '.join([str(sentence) for sentence in summary])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, df = df, tfidf_matrix = tfidf_matrix, top_n=5, summary_sentences=5):\n",
    "    relevant_indices, relevance_scores = find_unique_relevant_documents(query, tfidf_matrix, top_n)\n",
    "    relevant_docs = df.iloc[relevant_indices]\n",
    "    relevant_docs['relevance_score'] = relevance_scores\n",
    "    \n",
    "    # Keep only the rows with unique PMIDs\n",
    "    relevant_docs = relevant_docs.drop_duplicates(subset='PMID', ignore_index=True)\n",
    "    \n",
    "    # Combine all the full_text\n",
    "    combined_text = ' '.join(relevant_docs['full_text'].tolist())\n",
    "    \n",
    "    # Generate summary of the combined text\n",
    "    summary = summarize(combined_text, sentences_count=summary_sentences)\n",
    "    \n",
    "    return relevant_docs, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the rare diseases associated with the gene 'BRCA1'?\n",
      "Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Relapsing polychondritis (RP) is a rare autoimmune-related disease and may be associated with other autoimmune diseases. In the European Union (EU) a disease is considered to be rare if not more than 5 of 10,000 people are affected by it. In the present work most of the described diseases of salivary glands and of the facial nerve fall in this category. The work is a compilation of innate andacquired rare salivary gland disorders and of rare facial nerve disorders. Due to the rarity of these diseases, it is recommended to tread these in centers with special expertise for it.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Documents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>title</th>\n",
       "      <th>article_url</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35549688</td>\n",
       "      <td>Mutation analysis reveals novel and known muta...</td>\n",
       "      <td>https://doi.org/10.1002/Humu.24140</td>\n",
       "      <td>0.281202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36983602</td>\n",
       "      <td>Orphan Drugs in Neurology-A Narrative Review.</td>\n",
       "      <td>https://doi.org/10.1093/Brain/Awp294</td>\n",
       "      <td>0.273829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30290676</td>\n",
       "      <td>Case report of mixed-type autoimmune hemolytic...</td>\n",
       "      <td>https://doi.org/10.4103/Ajts.Ajts_74_19</td>\n",
       "      <td>0.273469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28877977</td>\n",
       "      <td>Rare pulmonary diseases: a common fight.</td>\n",
       "      <td>https://doi.org/10.1038/S41576-022-00478-5</td>\n",
       "      <td>0.269060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34352906</td>\n",
       "      <td>Rare Diseases of the Salivary Glands and of Fa...</td>\n",
       "      <td>https://doi.org/10.1055/A-1337-6994</td>\n",
       "      <td>0.241157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              title  \\\n",
       "0  35549688  Mutation analysis reveals novel and known muta...   \n",
       "1  36983602      Orphan Drugs in Neurology-A Narrative Review.   \n",
       "2  30290676  Case report of mixed-type autoimmune hemolytic...   \n",
       "3  28877977           Rare pulmonary diseases: a common fight.   \n",
       "4  34352906  Rare Diseases of the Salivary Glands and of Fa...   \n",
       "\n",
       "                                  article_url  relevance_score  \n",
       "0          https://doi.org/10.1002/Humu.24140         0.281202  \n",
       "1        https://doi.org/10.1093/Brain/Awp294         0.273829  \n",
       "2     https://doi.org/10.4103/Ajts.Ajts_74_19         0.273469  \n",
       "3  https://doi.org/10.1038/S41576-022-00478-5         0.269060  \n",
       "4         https://doi.org/10.1055/A-1337-6994         0.241157  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "query = \"What are the rare diseases associated with the gene 'BRCA1'?\"\n",
    "relevant_docs, summary = search_documents(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Summary:\")\n",
    "display(summary)\n",
    "print(f\"Relevant Documents:\")\n",
    "display(relevant_docs[['PMID', 'title','article_url','relevance_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
